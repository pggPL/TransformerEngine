{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334474ab-f7a3-439b-92d3-c331cebf488d",
   "metadata": {},
   "source": [
    "# Memory allocations on different streams in Pytorch with some parts of profiles \n",
    "\n",
    "\n",
    "I want to demonstrate the origins of cudaFree in profiles and attribute that to allocation on different stream than main.\n",
    "\n",
    "There are screenshots of some parts of the profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1f8003-e321-4d6a-9373-569a25141cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50887524352\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "total_mem = torch.cuda.get_device_properties(0).total_memory\n",
    "print(total_mem)\n",
    "\n",
    "to_alloc = int(0.9 * total_mem)\n",
    "\n",
    "# warm up alloc \n",
    "\n",
    "x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4443a0-7add-4b68-92c4-148d3baa93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without streams\n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "    del x\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8a55c-f162-43ee-8fbf-b0ac2d67f41e",
   "metadata": {},
   "source": [
    "The profile has no GPU operations - caching allocator works properly.\n",
    "<img src=\"./img/1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e817021-4cc6-436e-8ab6-e782ac76af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with streams, no sync\n",
    "\n",
    "s = torch.cuda.Stream()\n",
    "\n",
    "for _ in range(10):\n",
    "    with torch.cuda.stream(s):\n",
    "        x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "        del x\n",
    "    x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "    del x\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2becfad4-e5ee-4743-af0e-8da588826df8",
   "metadata": {},
   "source": [
    "There are malloc/free calls for every empty_call. This is zoom into one of them:\n",
    "\n",
    "\n",
    "<img src=\"./img/2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6160b0ef-7432-4114-a955-14ba3807f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with streams, sync\n",
    "\n",
    "s = torch.cuda.Stream()\n",
    "\n",
    "for _ in range(10):\n",
    "    with torch.cuda.stream(s):\n",
    "        x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "        del x\n",
    "    torch.cuda.synchronize()\n",
    "    x = torch.empty(to_alloc, dtype=torch.uint8, device=\"cuda\")\n",
    "    del x\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e2e4e-cf29-459d-9edc-061cd8e67166",
   "metadata": {},
   "source": [
    "There are malloc/free calls for every empty_call. This is zoom into one of them:\n",
    "\n",
    "<img src=\"./img/3.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
